// Code generated by protoc-gen-zig
///! package opentelemetry.proto.metrics.v1
const std = @import("std");
const Allocator = std.mem.Allocator;
const ArrayList = std.ArrayList;

const protobuf = @import("protobuf");
const ManagedString = protobuf.ManagedString;
const fd = protobuf.fd;
const ManagedStruct = protobuf.ManagedStruct;
const json = protobuf.json;
const UnionDecodingError = protobuf.UnionDecodingError;
/// import package opentelemetry.proto.common.v1
const opentelemetry_proto_common_v1 = @import("../common/v1.pb.zig");
/// import package opentelemetry.proto.resource.v1
const opentelemetry_proto_resource_v1 = @import("../resource/v1.pb.zig");

// AggregationTemporality defines how a metric aggregator reports aggregated
// values. It describes how those values relate to the time interval over
// which they are aggregated.
pub const AggregationTemporality = enum(i32) {
    // UNSPECIFIED is the default AggregationTemporality, it MUST not be used.
    AGGREGATION_TEMPORALITY_UNSPECIFIED = 0,
    // DELTA is an AggregationTemporality for a metric aggregator which reports
    // changes since last report time. Successive metrics contain aggregation of
    // values from continuous and non-overlapping intervals.
    //
    // The values for a DELTA metric are based only on the time interval
    // associated with one measurement cycle. There is no dependency on
    // previous measurements like is the case for CUMULATIVE metrics.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // DELTA metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0+1 to
    //      t_0+2 with a value of 2.
    AGGREGATION_TEMPORALITY_DELTA = 1,
    // CUMULATIVE is an AggregationTemporality for a metric aggregator which
    // reports changes since a fixed start time. This means that current values
    // of a CUMULATIVE metric depend on all previous measurements since the
    // start time. Because of this, the sender is required to retain this state
    // in some form. If this state is lost or invalidated, the CUMULATIVE metric
    // values MUST be reset and a new fixed start time following the last
    // reported measurement time sent MUST be used.
    //
    // For example, consider a system measuring the number of requests that
    // it receives and reports the sum of these requests every second as a
    // CUMULATIVE metric:
    //
    //   1. The system starts receiving at time=t_0.
    //   2. A request is received, the system measures 1 request.
    //   3. A request is received, the system measures 1 request.
    //   4. A request is received, the system measures 1 request.
    //   5. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+1 with a value of 3.
    //   6. A request is received, the system measures 1 request.
    //   7. A request is received, the system measures 1 request.
    //   8. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_0 to
    //      t_0+2 with a value of 5.
    //   9. The system experiences a fault and loses state.
    //   10. The system recovers and resumes receiving at time=t_1.
    //   11. A request is received, the system measures 1 request.
    //   12. The 1 second collection cycle ends. A metric is exported for the
    //      number of requests received over the interval of time t_1 to
    //      t_0+1 with a value of 1.
    //
    // Note: Even though, when reporting changes since last report time, using
    // CUMULATIVE is valid, it is not recommended. This may cause problems for
    // systems that do not use start_time to determine when the aggregation
    // value was reset (e.g. Prometheus).
    AGGREGATION_TEMPORALITY_CUMULATIVE = 2,
    _,
};

// DataPointFlags is defined as a protobuf 'uint32' type and is to be used as a
// bit-field representing 32 distinct boolean flags.  Each flag defined in this
// enum is a bit-mask.  To test the presence of a single flag in the flags of
// a data point, for example, use an expression like:
//
//   (point.flags & DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK) == DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK
pub const DataPointFlags = enum(i32) {
    // The zero value for the enum. Should not be used for comparisons.
    // Instead use bitwise "and" with the appropriate mask as shown above.
    DATA_POINT_FLAGS_DO_NOT_USE = 0,
    // This DataPoint is valid but has no recorded value.  This value
    // SHOULD be used to reflect explicitly missing data in a series, as
    // for an equivalent to the Prometheus "staleness marker".
    DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK = 1,
    _,
};

// MetricsData represents the metrics data that can be stored in a persistent
// storage, OR can be embedded by other protocols that transfer OTLP metrics
// data but do not implement the OTLP protocol.
//
// MetricsData
// └─── ResourceMetrics
//   ├── Resource
//   ├── SchemaURL
//   └── ScopeMetrics
//      ├── Scope
//      ├── SchemaURL
//      └── Metric
//         ├── Name
//         ├── Description
//         ├── Unit
//         └── data
//            ├── Gauge
//            ├── Sum
//            ├── Histogram
//            ├── ExponentialHistogram
//            └── Summary
//
// The main difference between this message and collector protocol is that
// in this message there will not be any "control" or "metadata" specific to
// OTLP protocol.
//
// When new fields are added into this message, the OTLP request MUST be updated
// as well.
pub const MetricsData = struct {
    // An array of ResourceMetrics.
    // For data coming from a single resource this array will typically contain
    // one element. Intermediary nodes that receive data from multiple origins
    // typically batch the data before forwarding further and in that case this
    // array will contain multiple elements.
    resource_metrics: ArrayList(ResourceMetrics),

    pub const _desc_table = .{
        .resource_metrics = fd(1, .{ .List = .{ .SubMessage = {} } }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// A collection of ScopeMetrics from a Resource.
pub const ResourceMetrics = struct {
    // The resource for the metrics in this message.
    // If this field is not set then no resource info is known.
    resource: ?opentelemetry_proto_resource_v1.Resource = null,
    // A list of metrics that originate from a resource.
    scope_metrics: ArrayList(ScopeMetrics),
    // The Schema URL, if known. This is the identifier of the Schema that the resource data
    // is recorded in. To learn more about Schema URL see
    // https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
    // This schema_url applies to the data in the "resource" field. It does not apply
    // to the data in the "scope_metrics" field which have their own schema_url field.
    schema_url: ManagedString = .Empty,

    pub const _desc_table = .{
        .resource = fd(1, .{ .SubMessage = {} }),
        .scope_metrics = fd(2, .{ .List = .{ .SubMessage = {} } }),
        .schema_url = fd(3, .String),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// A collection of Metrics produced by an Scope.
pub const ScopeMetrics = struct {
    // The instrumentation scope information for the metrics in this message.
    // Semantically when InstrumentationScope isn't set, it is equivalent with
    // an empty instrumentation scope name (unknown).
    scope: ?opentelemetry_proto_common_v1.InstrumentationScope = null,
    // A list of metrics that originate from an instrumentation library.
    metrics: ArrayList(Metric),
    // The Schema URL, if known. This is the identifier of the Schema that the metric data
    // is recorded in. To learn more about Schema URL see
    // https://opentelemetry.io/docs/specs/otel/schemas/#schema-url
    // This schema_url applies to all metrics in the "metrics" field.
    schema_url: ManagedString = .Empty,

    pub const _desc_table = .{
        .scope = fd(1, .{ .SubMessage = {} }),
        .metrics = fd(2, .{ .List = .{ .SubMessage = {} } }),
        .schema_url = fd(3, .String),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// Defines a Metric which has one or more timeseries.  The following is a
// brief summary of the Metric data model.  For more details, see:
//
//   https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md
//
// The data model and relation between entities is shown in the
// diagram below. Here, "DataPoint" is the term used to refer to any
// one of the specific data point value types, and "points" is the term used
// to refer to any one of the lists of points contained in the Metric.
//
// - Metric is composed of a metadata and data.
// - Metadata part contains a name, description, unit.
// - Data is one of the possible types (Sum, Gauge, Histogram, Summary).
// - DataPoint contains timestamps, attributes, and one of the possible value type
//   fields.
//
//    Metric
//  +------------+
//  |name        |
//  |description |
//  |unit        |     +------------------------------------+
//  |data        |---> |Gauge, Sum, Histogram, Summary, ... |
//  +------------+     +------------------------------------+
//
//    Data [One of Gauge, Sum, Histogram, Summary, ...]
//  +-----------+
//  |...        |  // Metadata about the Data.
//  |points     |--+
//  +-----------+  |
//                 |      +---------------------------+
//                 |      |DataPoint 1                |
//                 v      |+------+------+   +------+ |
//              +-----+   ||label |label |...|label | |
//              |  1  |-->||value1|value2|...|valueN| |
//              +-----+   |+------+------+   +------+ |
//              |  .  |   |+-----+                    |
//              |  .  |   ||value|                    |
//              |  .  |   |+-----+                    |
//              |  .  |   +---------------------------+
//              |  .  |                   .
//              |  .  |                   .
//              |  .  |                   .
//              |  .  |   +---------------------------+
//              |  .  |   |DataPoint M                |
//              +-----+   |+------+------+   +------+ |
//              |  M  |-->||label |label |...|label | |
//              +-----+   ||value1|value2|...|valueN| |
//                        |+------+------+   +------+ |
//                        |+-----+                    |
//                        ||value|                    |
//                        |+-----+                    |
//                        +---------------------------+
//
// Each distinct type of DataPoint represents the output of a specific
// aggregation function, the result of applying the DataPoint's
// associated function of to one or more measurements.
//
// All DataPoint types have three common fields:
// - Attributes includes key-value pairs associated with the data point
// - TimeUnixNano is required, set to the end time of the aggregation
// - StartTimeUnixNano is optional, but strongly encouraged for DataPoints
//   having an AggregationTemporality field, as discussed below.
//
// Both TimeUnixNano and StartTimeUnixNano values are expressed as
// UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.
//
// # TimeUnixNano
//
// This field is required, having consistent interpretation across
// DataPoint types.  TimeUnixNano is the moment corresponding to when
// the data point's aggregate value was captured.
//
// Data points with the 0 value for TimeUnixNano SHOULD be rejected
// by consumers.
//
// # StartTimeUnixNano
//
// StartTimeUnixNano in general allows detecting when a sequence of
// observations is unbroken.  This field indicates to consumers the
// start time for points with cumulative and delta
// AggregationTemporality, and it should be included whenever possible
// to support correct rate calculation.  Although it may be omitted
// when the start time is truly unknown, setting StartTimeUnixNano is
// strongly encouraged.
pub const Metric = struct {
    // name of the metric.
    name: ManagedString = .Empty,
    // description of the metric, which can be used in documentation.
    description: ManagedString = .Empty,
    // unit in which the metric value is reported. Follows the format
    // described by http://unitsofmeasure.org/ucum.html.
    unit: ManagedString = .Empty,
    // Additional metadata attributes that describe the metric. [Optional].
    // Attributes are non-identifying.
    // Consumers SHOULD NOT need to be aware of these attributes.
    // These attributes MAY be used to encode information allowing
    // for lossless roundtrip translation to / from another data model.
    // Attribute keys MUST be unique (it is not allowed to have more than one
    // attribute with the same key).
    metadata: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // Data determines the aggregation type (if any) of the metric, what is the
    // reported value type for the data points, as well as the relatationship to
    // the time interval over which they are reported.
    data: ?data_union,

    pub const _data_case = enum {
        gauge,
        sum,
        histogram,
        exponential_histogram,
        summary,
    };
    pub const data_union = union(_data_case) {
        gauge: Gauge,
        sum: Sum,
        histogram: Histogram,
        exponential_histogram: ExponentialHistogram,
        summary: Summary,
        pub const _union_desc = .{
            .gauge = fd(5, .{ .SubMessage = {} }),
            .sum = fd(7, .{ .SubMessage = {} }),
            .histogram = fd(9, .{ .SubMessage = {} }),
            .exponential_histogram = fd(10, .{ .SubMessage = {} }),
            .summary = fd(11, .{ .SubMessage = {} }),
        };
    };

    pub const _desc_table = .{
        .name = fd(1, .String),
        .description = fd(2, .String),
        .unit = fd(3, .String),
        .metadata = fd(12, .{ .List = .{ .SubMessage = {} } }),
        .data = fd(null, .{ .OneOf = data_union }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// Gauge represents the type of a scalar metric that always exports the
// "current value" for every data point. It should be used for an "unknown"
// aggregation.
//
// A Gauge does not support different aggregation temporalities. Given the
// aggregation is unknown, points cannot be combined using the same
// aggregation, regardless of aggregation temporalities. Therefore,
// AggregationTemporality is not included. Consequently, this also means
// "StartTimeUnixNano" is ignored for all data points.
pub const Gauge = struct {
    data_points: ArrayList(NumberDataPoint),

    pub const _desc_table = .{
        .data_points = fd(1, .{ .List = .{ .SubMessage = {} } }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// Sum represents the type of a scalar metric that is calculated as a sum of all
// reported measurements over a time interval.
pub const Sum = struct {
    data_points: ArrayList(NumberDataPoint),
    // aggregation_temporality describes if the aggregator reports delta changes
    // since last report time, or cumulative changes since a fixed start time.
    aggregation_temporality: AggregationTemporality = @enumFromInt(0),
    // If "true" means that the sum is monotonic.
    is_monotonic: bool = false,

    pub const _desc_table = .{
        .data_points = fd(1, .{ .List = .{ .SubMessage = {} } }),
        .aggregation_temporality = fd(2, .{ .Varint = .Simple }),
        .is_monotonic = fd(3, .{ .Varint = .Simple }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// Histogram represents the type of a metric that is calculated by aggregating
// as a Histogram of all reported measurements over a time interval.
pub const Histogram = struct {
    data_points: ArrayList(HistogramDataPoint),
    // aggregation_temporality describes if the aggregator reports delta changes
    // since last report time, or cumulative changes since a fixed start time.
    aggregation_temporality: AggregationTemporality = @enumFromInt(0),

    pub const _desc_table = .{
        .data_points = fd(1, .{ .List = .{ .SubMessage = {} } }),
        .aggregation_temporality = fd(2, .{ .Varint = .Simple }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// ExponentialHistogram represents the type of a metric that is calculated by aggregating
// as a ExponentialHistogram of all reported double measurements over a time interval.
pub const ExponentialHistogram = struct {
    data_points: ArrayList(ExponentialHistogramDataPoint),
    // aggregation_temporality describes if the aggregator reports delta changes
    // since last report time, or cumulative changes since a fixed start time.
    aggregation_temporality: AggregationTemporality = @enumFromInt(0),

    pub const _desc_table = .{
        .data_points = fd(1, .{ .List = .{ .SubMessage = {} } }),
        .aggregation_temporality = fd(2, .{ .Varint = .Simple }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// Summary metric data are used to convey quantile summaries,
// a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)
// and OpenMetrics (see: https://github.com/OpenObservability/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)
// data type. These data points cannot always be merged in a meaningful way.
// While they can be useful in some applications, histogram data points are
// recommended for new applications.
pub const Summary = struct {
    data_points: ArrayList(SummaryDataPoint),

    pub const _desc_table = .{
        .data_points = fd(1, .{ .List = .{ .SubMessage = {} } }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// NumberDataPoint is a single data point in a timeseries that describes the
// time-varying scalar value of a metric.
pub const NumberDataPoint = struct {
    // The set of key/value pairs that uniquely identify the timeseries from
    // where this point belongs. The list may be empty (may contain 0 elements).
    // Attribute keys MUST be unique (it is not allowed to have more than one
    // attribute with the same key).
    attributes: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // StartTimeUnixNano is optional but strongly encouraged, see the
    // the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    start_time_unix_nano: u64 = 0,
    // TimeUnixNano is required, see the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    time_unix_nano: u64 = 0,
    // (Optional) List of exemplars collected from
    // measurements that were used to form the data point
    exemplars: ArrayList(Exemplar),
    // Flags that apply to this specific data point.  See DataPointFlags
    // for the available flags and their meaning.
    flags: u32 = 0,
    // The value itself.  A point is considered invalid when one of the recognized
    // value fields is not present inside this oneof.
    value: ?value_union,

    pub const _value_case = enum {
        as_double,
        as_int,
    };
    pub const value_union = union(_value_case) {
        as_double: f64,
        as_int: i64,
        pub const _union_desc = .{
            .as_double = fd(4, .{ .FixedInt = .I64 }),
            .as_int = fd(6, .{ .FixedInt = .I64 }),
        };
    };

    pub const _desc_table = .{
        .attributes = fd(7, .{ .List = .{ .SubMessage = {} } }),
        .start_time_unix_nano = fd(2, .{ .FixedInt = .I64 }),
        .time_unix_nano = fd(3, .{ .FixedInt = .I64 }),
        .exemplars = fd(5, .{ .List = .{ .SubMessage = {} } }),
        .flags = fd(8, .{ .Varint = .Simple }),
        .value = fd(null, .{ .OneOf = value_union }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// HistogramDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Histogram. A Histogram contains summary statistics
// for a population of values, it may optionally contain the distribution of
// those values across a set of buckets.
//
// If the histogram contains the distribution of values, then both
// "explicit_bounds" and "bucket counts" fields must be defined.
// If the histogram does not contain the distribution of values, then both
// "explicit_bounds" and "bucket_counts" must be omitted and only "count" and
// "sum" are known.
pub const HistogramDataPoint = struct {
    // The set of key/value pairs that uniquely identify the timeseries from
    // where this point belongs. The list may be empty (may contain 0 elements).
    // Attribute keys MUST be unique (it is not allowed to have more than one
    // attribute with the same key).
    attributes: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // StartTimeUnixNano is optional but strongly encouraged, see the
    // the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    start_time_unix_nano: u64 = 0,
    // TimeUnixNano is required, see the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    time_unix_nano: u64 = 0,
    // count is the number of values in the population. Must be non-negative. This
    // value must be equal to the sum of the "count" fields in buckets if a
    // histogram is provided.
    count: u64 = 0,
    // sum of the values in the population. If count is zero then this field
    // must be zero.
    //
    // Note: Sum should only be filled out when measuring non-negative discrete
    // events, and is assumed to be monotonic over the values of these events.
    // Negative events *can* be recorded, but sum should not be filled out when
    // doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
    // see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#histogram
    sum: ?f64 = null,
    // bucket_counts is an optional field contains the count values of histogram
    // for each bucket.
    //
    // The sum of the bucket_counts must equal the value in the count field.
    //
    // The number of elements in bucket_counts array must be by one greater than
    // the number of elements in explicit_bounds array.
    bucket_counts: ArrayList(u64),
    // explicit_bounds specifies buckets with explicitly defined bounds for values.
    //
    // The boundaries for bucket at index i are:
    //
    // (-infinity, explicit_bounds[i]] for i == 0
    // (explicit_bounds[i-1], explicit_bounds[i]] for 0 < i < size(explicit_bounds)
    // (explicit_bounds[i-1], +infinity) for i == size(explicit_bounds)
    //
    // The values in the explicit_bounds array must be strictly increasing.
    //
    // Histogram buckets are inclusive of their upper boundary, except the last
    // bucket where the boundary is at infinity. This format is intentionally
    // compatible with the OpenMetrics histogram definition.
    explicit_bounds: ArrayList(f64),
    // (Optional) List of exemplars collected from
    // measurements that were used to form the data point
    exemplars: ArrayList(Exemplar),
    // Flags that apply to this specific data point.  See DataPointFlags
    // for the available flags and their meaning.
    flags: u32 = 0,
    // min is the minimum value over (start_time, end_time].
    min: ?f64 = null,
    // max is the maximum value over (start_time, end_time].
    max: ?f64 = null,

    pub const _desc_table = .{
        .attributes = fd(9, .{ .List = .{ .SubMessage = {} } }),
        .start_time_unix_nano = fd(2, .{ .FixedInt = .I64 }),
        .time_unix_nano = fd(3, .{ .FixedInt = .I64 }),
        .count = fd(4, .{ .FixedInt = .I64 }),
        .sum = fd(5, .{ .FixedInt = .I64 }),
        .bucket_counts = fd(6, .{ .PackedList = .{ .FixedInt = .I64 } }),
        .explicit_bounds = fd(7, .{ .PackedList = .{ .FixedInt = .I64 } }),
        .exemplars = fd(8, .{ .List = .{ .SubMessage = {} } }),
        .flags = fd(10, .{ .Varint = .Simple }),
        .min = fd(11, .{ .FixedInt = .I64 }),
        .max = fd(12, .{ .FixedInt = .I64 }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// ExponentialHistogramDataPoint is a single data point in a timeseries that describes the
// time-varying values of a ExponentialHistogram of double values. A ExponentialHistogram contains
// summary statistics for a population of values, it may optionally contain the
// distribution of those values across a set of buckets.
pub const ExponentialHistogramDataPoint = struct {
    // The set of key/value pairs that uniquely identify the timeseries from
    // where this point belongs. The list may be empty (may contain 0 elements).
    // Attribute keys MUST be unique (it is not allowed to have more than one
    // attribute with the same key).
    attributes: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // StartTimeUnixNano is optional but strongly encouraged, see the
    // the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    start_time_unix_nano: u64 = 0,
    // TimeUnixNano is required, see the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    time_unix_nano: u64 = 0,
    // count is the number of values in the population. Must be
    // non-negative. This value must be equal to the sum of the "bucket_counts"
    // values in the positive and negative Buckets plus the "zero_count" field.
    count: u64 = 0,
    // sum of the values in the population. If count is zero then this field
    // must be zero.
    //
    // Note: Sum should only be filled out when measuring non-negative discrete
    // events, and is assumed to be monotonic over the values of these events.
    // Negative events *can* be recorded, but sum should not be filled out when
    // doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
    // see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#histogram
    sum: ?f64 = null,
    // scale describes the resolution of the histogram.  Boundaries are
    // located at powers of the base, where:
    //
    //   base = (2^(2^-scale))
    //
    // The histogram bucket identified by `index`, a signed integer,
    // contains values that are greater than (base^index) and
    // less than or equal to (base^(index+1)).
    //
    // The positive and negative ranges of the histogram are expressed
    // separately.  Negative values are mapped by their absolute value
    // into the negative range using the same scale as the positive range.
    //
    // scale is not restricted by the protocol, as the permissible
    // values depend on the range of the data.
    scale: i32 = 0,
    // zero_count is the count of values that are either exactly zero or
    // within the region considered zero by the instrumentation at the
    // tolerated degree of precision.  This bucket stores values that
    // cannot be expressed using the standard exponential formula as
    // well as values that have been rounded to zero.
    //
    // Implementations MAY consider the zero bucket to have probability
    // mass equal to (zero_count / count).
    zero_count: u64 = 0,
    // positive carries the positive range of exponential bucket counts.
    positive: ?ExponentialHistogramDataPoint.Buckets = null,
    // negative carries the negative range of exponential bucket counts.
    negative: ?ExponentialHistogramDataPoint.Buckets = null,
    // Flags that apply to this specific data point.  See DataPointFlags
    // for the available flags and their meaning.
    flags: u32 = 0,
    // (Optional) List of exemplars collected from
    // measurements that were used to form the data point
    exemplars: ArrayList(Exemplar),
    // min is the minimum value over (start_time, end_time].
    min: ?f64 = null,
    // max is the maximum value over (start_time, end_time].
    max: ?f64 = null,
    // ZeroThreshold may be optionally set to convey the width of the zero
    // region. Where the zero region is defined as the closed interval
    // [-ZeroThreshold, ZeroThreshold].
    // When ZeroThreshold is 0, zero count bucket stores values that cannot be
    // expressed using the standard exponential formula as well as values that
    // have been rounded to zero.
    zero_threshold: f64 = 0,

    pub const _desc_table = .{
        .attributes = fd(1, .{ .List = .{ .SubMessage = {} } }),
        .start_time_unix_nano = fd(2, .{ .FixedInt = .I64 }),
        .time_unix_nano = fd(3, .{ .FixedInt = .I64 }),
        .count = fd(4, .{ .FixedInt = .I64 }),
        .sum = fd(5, .{ .FixedInt = .I64 }),
        .scale = fd(6, .{ .Varint = .ZigZagOptimized }),
        .zero_count = fd(7, .{ .FixedInt = .I64 }),
        .positive = fd(8, .{ .SubMessage = {} }),
        .negative = fd(9, .{ .SubMessage = {} }),
        .flags = fd(10, .{ .Varint = .Simple }),
        .exemplars = fd(11, .{ .List = .{ .SubMessage = {} } }),
        .min = fd(12, .{ .FixedInt = .I64 }),
        .max = fd(13, .{ .FixedInt = .I64 }),
        .zero_threshold = fd(14, .{ .FixedInt = .I64 }),
    };

    // Buckets are a set of bucket counts, encoded in a contiguous array
    // of counts.
    pub const Buckets = struct {
        // Offset is the bucket index of the first entry in the bucket_counts array.
        //
        // Note: This uses a varint encoding as a simple form of compression.
        offset: i32 = 0,
        // bucket_counts is an array of count values, where bucket_counts[i] carries
        // the count of the bucket at index (offset+i). bucket_counts[i] is the count
        // of values greater than base^(offset+i) and less than or equal to
        // base^(offset+i+1).
        //
        // Note: By contrast, the explicit HistogramDataPoint uses
        // fixed64.  This field is expected to have many buckets,
        // especially zeros, so uint64 has been selected to ensure
        // varint encoding.
        bucket_counts: ArrayList(u64),

        pub const _desc_table = .{
            .offset = fd(1, .{ .Varint = .ZigZagOptimized }),
            .bucket_counts = fd(2, .{ .PackedList = .{ .Varint = .Simple } }),
        };

        pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
            return protobuf.pb_encode(self, allocator);
        }
        pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
            return protobuf.pb_decode(@This(), input, allocator);
        }
        pub fn init(allocator: Allocator) @This() {
            return protobuf.pb_init(@This(), allocator);
        }
        pub fn deinit(self: @This()) void {
            return protobuf.pb_deinit(self);
        }
        pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
            return protobuf.pb_dupe(@This(), self, allocator);
        }
        pub fn json_decode(
            input: []const u8,
            options: json.ParseOptions,
            allocator: Allocator,
        ) !std.json.Parsed(@This()) {
            return protobuf.pb_json_decode(@This(), input, options, allocator);
        }
        pub fn json_encode(
            self: @This(),
            options: json.Stringify.Options,
            allocator: Allocator,
        ) ![]const u8 {
            return protobuf.pb_json_encode(self, options, allocator);
        }

        // This method is used by std.json
        // internally for deserialization. DO NOT RENAME!
        pub fn jsonParse(
            allocator: Allocator,
            source: anytype,
            options: json.ParseOptions,
        ) !@This() {
            return protobuf.pb_json_parse(@This(), allocator, source, options);
        }

        // This method is used by std.json
        // internally for serialization. DO NOT RENAME!
        pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
            return protobuf.pb_jsonStringify(@This(), self, jws);
        }
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// SummaryDataPoint is a single data point in a timeseries that describes the
// time-varying values of a Summary metric.
pub const SummaryDataPoint = struct {
    // The set of key/value pairs that uniquely identify the timeseries from
    // where this point belongs. The list may be empty (may contain 0 elements).
    // Attribute keys MUST be unique (it is not allowed to have more than one
    // attribute with the same key).
    attributes: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // StartTimeUnixNano is optional but strongly encouraged, see the
    // the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    start_time_unix_nano: u64 = 0,
    // TimeUnixNano is required, see the detailed comments above Metric.
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    time_unix_nano: u64 = 0,
    // count is the number of values in the population. Must be non-negative.
    count: u64 = 0,
    // sum of the values in the population. If count is zero then this field
    // must be zero.
    //
    // Note: Sum should only be filled out when measuring non-negative discrete
    // events, and is assumed to be monotonic over the values of these events.
    // Negative events *can* be recorded, but sum should not be filled out when
    // doing so.  This is specifically to enforce compatibility w/ OpenMetrics,
    // see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#summary
    sum: f64 = 0,
    // (Optional) list of values at different quantiles of the distribution calculated
    // from the current snapshot. The quantiles must be strictly increasing.
    quantile_values: ArrayList(SummaryDataPoint.ValueAtQuantile),
    // Flags that apply to this specific data point.  See DataPointFlags
    // for the available flags and their meaning.
    flags: u32 = 0,

    pub const _desc_table = .{
        .attributes = fd(7, .{ .List = .{ .SubMessage = {} } }),
        .start_time_unix_nano = fd(2, .{ .FixedInt = .I64 }),
        .time_unix_nano = fd(3, .{ .FixedInt = .I64 }),
        .count = fd(4, .{ .FixedInt = .I64 }),
        .sum = fd(5, .{ .FixedInt = .I64 }),
        .quantile_values = fd(6, .{ .List = .{ .SubMessage = {} } }),
        .flags = fd(8, .{ .Varint = .Simple }),
    };

    // Represents the value at a given quantile of a distribution.
    //
    // To record Min and Max values following conventions are used:
    // - The 1.0 quantile is equivalent to the maximum value observed.
    // - The 0.0 quantile is equivalent to the minimum value observed.
    //
    // See the following issue for more context:
    // https://github.com/open-telemetry/opentelemetry-proto/issues/125
    pub const ValueAtQuantile = struct {
        // The quantile of a distribution. Must be in the interval
        // [0.0, 1.0].
        quantile: f64 = 0,
        // The value at the given quantile of a distribution.
        //
        // Quantile values must NOT be negative.
        value: f64 = 0,

        pub const _desc_table = .{
            .quantile = fd(1, .{ .FixedInt = .I64 }),
            .value = fd(2, .{ .FixedInt = .I64 }),
        };

        pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
            return protobuf.pb_encode(self, allocator);
        }
        pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
            return protobuf.pb_decode(@This(), input, allocator);
        }
        pub fn init(allocator: Allocator) @This() {
            return protobuf.pb_init(@This(), allocator);
        }
        pub fn deinit(self: @This()) void {
            return protobuf.pb_deinit(self);
        }
        pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
            return protobuf.pb_dupe(@This(), self, allocator);
        }
        pub fn json_decode(
            input: []const u8,
            options: json.ParseOptions,
            allocator: Allocator,
        ) !std.json.Parsed(@This()) {
            return protobuf.pb_json_decode(@This(), input, options, allocator);
        }
        pub fn json_encode(
            self: @This(),
            options: json.Stringify.Options,
            allocator: Allocator,
        ) ![]const u8 {
            return protobuf.pb_json_encode(self, options, allocator);
        }

        // This method is used by std.json
        // internally for deserialization. DO NOT RENAME!
        pub fn jsonParse(
            allocator: Allocator,
            source: anytype,
            options: json.ParseOptions,
        ) !@This() {
            return protobuf.pb_json_parse(@This(), allocator, source, options);
        }

        // This method is used by std.json
        // internally for serialization. DO NOT RENAME!
        pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
            return protobuf.pb_jsonStringify(@This(), self, jws);
        }
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};

// A representation of an exemplar, which is a sample input measurement.
// Exemplars also hold information about the environment when the measurement
// was recorded, for example the span and trace ID of the active span when the
// exemplar was recorded.
pub const Exemplar = struct {
    // The set of key/value pairs that were filtered out by the aggregator, but
    // recorded alongside the original measurement. Only key/value pairs that were
    // filtered out by the aggregator should be included
    filtered_attributes: ArrayList(opentelemetry_proto_common_v1.KeyValue),
    // time_unix_nano is the exact time when this exemplar was recorded
    //
    // Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January
    // 1970.
    time_unix_nano: u64 = 0,
    // (Optional) Span ID of the exemplar trace.
    // span_id may be missing if the measurement is not recorded inside a trace
    // or if the trace is not sampled.
    span_id: ManagedString = .Empty,
    // (Optional) Trace ID of the exemplar trace.
    // trace_id may be missing if the measurement is not recorded inside a trace
    // or if the trace is not sampled.
    trace_id: ManagedString = .Empty,
    // The value of the measurement that was recorded. An exemplar is
    // considered invalid when one of the recognized value fields is not present
    // inside this oneof.
    value: ?value_union,

    pub const _value_case = enum {
        as_double,
        as_int,
    };
    pub const value_union = union(_value_case) {
        as_double: f64,
        as_int: i64,
        pub const _union_desc = .{
            .as_double = fd(3, .{ .FixedInt = .I64 }),
            .as_int = fd(6, .{ .FixedInt = .I64 }),
        };
    };

    pub const _desc_table = .{
        .filtered_attributes = fd(7, .{ .List = .{ .SubMessage = {} } }),
        .time_unix_nano = fd(2, .{ .FixedInt = .I64 }),
        .span_id = fd(4, .Bytes),
        .trace_id = fd(5, .Bytes),
        .value = fd(null, .{ .OneOf = value_union }),
    };

    pub fn encode(self: @This(), allocator: Allocator) Allocator.Error![]u8 {
        return protobuf.pb_encode(self, allocator);
    }
    pub fn decode(input: []const u8, allocator: Allocator) UnionDecodingError!@This() {
        return protobuf.pb_decode(@This(), input, allocator);
    }
    pub fn init(allocator: Allocator) @This() {
        return protobuf.pb_init(@This(), allocator);
    }
    pub fn deinit(self: @This()) void {
        return protobuf.pb_deinit(self);
    }
    pub fn dupe(self: @This(), allocator: Allocator) Allocator.Error!@This() {
        return protobuf.pb_dupe(@This(), self, allocator);
    }
    pub fn json_decode(
        input: []const u8,
        options: json.ParseOptions,
        allocator: Allocator,
    ) !std.json.Parsed(@This()) {
        return protobuf.pb_json_decode(@This(), input, options, allocator);
    }
    pub fn json_encode(
        self: @This(),
        options: json.Stringify.Options,
        allocator: Allocator,
    ) ![]const u8 {
        return protobuf.pb_json_encode(self, options, allocator);
    }

    // This method is used by std.json
    // internally for deserialization. DO NOT RENAME!
    pub fn jsonParse(
        allocator: Allocator,
        source: anytype,
        options: json.ParseOptions,
    ) !@This() {
        return protobuf.pb_json_parse(@This(), allocator, source, options);
    }

    // This method is used by std.json
    // internally for serialization. DO NOT RENAME!
    pub fn jsonStringify(self: *const @This(), jws: anytype) !void {
        return protobuf.pb_jsonStringify(@This(), self, jws);
    }
};
